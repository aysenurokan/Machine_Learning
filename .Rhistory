knitr::opts_chunk$set(echo = TRUE)
library(rpart)
library(rpart.plot)
library(partykit)
library(caret)
library(e1071)
library(party)
library(randomForest)
library(readr)
library(tidyverse)
#"sgroup", "sex", "marital", "gender", "ethnicity", "education", "race",
setwd("/Users/aysenur/Documents/GitHub/Machine_Learning/Final Project")
df <- read_csv("/Users/aysenur/Documents/GitHub/Machine_Learning/Final Project/ml_df.csv")
df <- df %>% dplyr::select(-PDWEMA, -SIEMA, - c("interperinteract_yesno", "SI", "surveytype", "EMA_SIdod", "sgroup"))
df <- na.omit(df)
df <- df[2:27]
View(df)
df <- df[2:26]
df$SI_Binary<- factor(df$SI_Binary) #pools together passive and active SI
#df$PDWEMA <- factor(df$PDWEMA) #Passive SI
#df$SIEMA <- factor(df$SIEMA) #Active SI
#check that all predictors are numeric
str(df)
#Split data into training and testing
set.seed(150) # Set a seed for reproducibility
index <- createDataPartition(df$SI_Binary, p = 0.5, list = FALSE) # Create an index for splitting the data; use 50% for training and 50% for testing
# Create training and testing datasets
df <- df[index, ] #training data
tsdf <- df[-index, ] #testing data
names(df)
knitr::opts_chunk$set(echo = TRUE)
library(rpart)
library(rpart.plot)
library(partykit)
library(caret)
library(e1071)
library(party)
library(randomForest)
library(readr)
library(tidyverse)
#"sgroup", "sex", "marital", "gender", "ethnicity", "education", "race",
setwd("/Users/aysenur/Documents/GitHub/Machine_Learning/Final Project")
df <- read_csv("/Users/aysenur/Documents/GitHub/Machine_Learning/Final Project/ml_df.csv")
df <- df %>% dplyr::select(-PDWEMA, -SIEMA, - c("interperinteract_yesno", "SI", "surveytype", "EMA_SIdod", "sgroup"))
df <- na.omit(df)
df <- df[2:26]
df$SI_Binary<- factor(df$SI_Binary) #pools together passive and active SI
df <- df (apply function(factor), c("sex", "race", "ethnicity", "marital", "gender", ))
df <- df %>% lapply(c("sex", "race", "ethnicity", "marital", "gender"), factor())
df <- df %>% lapply(c("sex", "race", "ethnicity", "marital", "gender"), factor
df <- df %>% lapply(c("sex", "race", "ethnicity", "marital", "gender"), factor)
columns_to_factor <- c("sex", "race", "ethnicity", "marital", "gender")
df[columns_to_factor] <- lapply(df[columns_to_factor], factor)
#check that all predictors are numeric
str(df)
knitr::opts_chunk$set(echo = TRUE)
library(rpart)
library(rpart.plot)
library(partykit)
library(caret)
library(e1071)
library(party)
library(randomForest)
library(readr)
library(tidyverse)
#"sgroup", "sex", "marital", "gender", "ethnicity", "education", "race",
setwd("/Users/aysenur/Documents/GitHub/Machine_Learning/Final Project")
df <- read_csv("/Users/aysenur/Documents/GitHub/Machine_Learning/Final Project/ml_df.csv")
df <- df %>% dplyr::select(-PDWEMA, -SIEMA, - c("interperinteract_yesno", "SI", "surveytype", "EMA_SIdod", "sgroup"))
df <- na.omit(df)
df <- df[2:26]
df$SI_Binary <- factor(df$SI_Binary) #pools together passive and active SI
columns_to_factor <- c("sex", "race", "ethnicity", "marital", "gender")
df[columns_to_factor] <- lapply(df[columns_to_factor], factor)
#df$PDWEMA <- factor(df$PDWEMA) #Passive SI
#df$SIEMA <- factor(df$SIEMA) #Active SI
#check that all predictors are numeric
str(df)
#Split data into training and testing
set.seed(150) # Set a seed for reproducibility
index <- createDataPartition(df$SI_Binary, p = 0.5, list = FALSE) # Create an index for splitting the data; use 50% for training and 50% for testing
# Create training and testing datasets
df <- df[index, ] #training data
tsdf <- df[-index, ] #testing data
set.seed(41)
tree.rpart=rpart(SI_Binary~. -id,data=df) #predict suicidal ideation choice from all predictors
prp(tree.rpart) #plot the decision tree
plotcp(tree.rpart)
#(1 s.e. from minimum error in the left out fold)
printcp(tree.rpart) #similar, but now with numbers, not the plot
tree.rpartp=prune(tree.rpart,cp=.013) #extract the tree with the determined complexity parameter; #adding "p" to signal that it is the pruned one
prp(tree.rpartp) #plot the pruned tree
#prediction error for full tree
pred.rpart=predict(tree.rpart,newdata=tsdf,type='class') #predicted values
table(pred.rpart,tsdf$SI_Binary) #cross-tabulation table (observed values are in columns)
miss.rpart=1-mean(pred.rpart==tsdf$SI_Binary, na.rm = T) #0-1 loss
miss.rpart # misclassification rate
#prediction error for pruned tree
pred.rpartp=predict(tree.rpartp,newdata=tsdf,type='class')
table(pred.rpartp,tsdf$SI_Binary)
miss.rpartp=1-mean(pred.rpartp==tsdf$SI_Binary, na.rm = T)
miss.rpartp
bag1=randomForest(SI_Binary~.-id,data=df,mtry=7,ntree=500) #bagging model; `mtry` function argument controls the number of predictors considered every time the tree makes a split. If the `mtry` values equals the number of predictors, then the randomForest function does bagging.
bagpred=predict(bag1,tsdf,type='response') #obtain predicted values from testing dataset
bag.table=table(bagpred,tsdf$SI_Binary) #cross-tabulation (rows are predicted, columns are observed
bag.table
1-(mean(bagpred==tsdf$SI_Binary))
varImpPlot(bag1) #plot variable importance measures
# Predicting SI_Binary with random forest on the training dataset
rf1=randomForest(SI_Binary~.-id,data=df,mtry=3,ntree=400) #use 3 vars at a time (3 random predictors as candidates to split on), 400 trees grown in bootstrapped datasets.
#obtain the predicted values in the testing dataset
rfpred=predict(rf1,tsdf,type='response')
# cross-tabulation of the classes
rf.table=table(rfpred,tsdf$SI_Binary)
#the variable importance measures.
rf.table
1-(mean(rfpred==tsdf$SI_Binary))
varImpPlot(rf1)
df[] <- lapply(df, function(x) if(is.character(x)) factor(x) else x)
tsdf[] <- lapply(tsdf, function(x) if(is.character(x)) factor(x) else x)
crf1 <- cforest(SI_Binary ~ . - id, data = df, controls = cforest_unbiased(ntree = 400, mtry = 3))
# Make predictions on the testing dataset
#crfpred <- predict(crf1, newdata = tsdf, type = "response") # Error in checkData(oldData, RET) :  Levels in factors of new data do not match original data -- I checked and the levels of the race variable are different. This is because there is only one American Indian participant in the entire dataset and they were added to the training data.
#filter out the American Indian participant
df <- df %>% filter(race != "American Indian")
df$race <- factor(as.character(df$race, levels = "African American", "Asian","Pacific Islander" ,"White"))
df[] <- lapply(df, function(x) if(is.character(x)) factor(x) else x)
crf1 <- cforest(SI_Binary ~ . - id, data = df, controls = cforest_unbiased(ntree = 400, mtry = 3))
crfpred <- predict(crf1, newdata = tsdf, type = "response")
levels(tsdf$rCW)
levels(tsdf$race)
levels(df$race)
View(tsdf %>% filter(race == "American Indian"))
df[] <- lapply(df, function(x) if(is.character(x)) factor(x) else x)
tsdf[] <- lapply(tsdf, function(x) if(is.character(x)) factor(x) else x)
crf1 <- cforest(SI_Binary ~ . - id, data = df, controls = cforest_unbiased(ntree = 400, mtry = 3))
# Make predictions on the testing dataset
#crfpred <- predict(crf1, newdata = tsdf, type = "response") # Error in checkData(oldData, RET) :  Levels in factors of new data do not match original data -- I checked and the levels of the race variable are different. This is because there is only one American Indian participant in the entire dataset and they were added to the training data.
#filter out the American Indian participant
df <- df %>% filter(race != "American Indian")
df$race <- factor(as.character(df$race, levels = "African American", "Asian","Pacific Islander" ,"White"))
tsdf$race <- factor(as.character(tsdf$race, levels = "African American", "Asian","Pacific Islander" ,"White"))
df[] <- lapply(df, function(x) if(is.character(x)) factor(x) else x)
crf1 <- cforest(SI_Binary ~ . - id, data = df, controls = cforest_unbiased(ntree = 400, mtry = 3))
crfpred <- predict(crf1, newdata = tsdf, type = "response")
crf.table=table(crfpred,tsdf$SI_Binary)
crf.table
1-(mean(crfpred==tsdf$SI_Binary))
vi=varimp(crf1)
dotchart(sort(vi,decreasing=FALSE))
trctrl=trainControl(method='cv',number=5) #k-fold cross-validation to determine the tuning parameters.
set.seed(2000)
#Fit Model
train.rf=train(SI_Binary~.,data=df,method='rf',tuneLength=5,trControl=trctrl)
#See tuning parameters
train.rf
plot(train.rf)
final.rf=train.rf$finalModel
varImpPlot(final.rf)
#Fit model for conditional inference random forest
set.seed(2000)
train.crf=train(SI_Binary~.,data=df,method='cforest',tuneLength=5,trControl=trctrl)
train.crf
plot(train.crf)
final.crf=train.crf$finalModel
#plot variable importance
vi=varImp(final.crf)[,1]
names(vi)=rownames(varImp(final.crf))
dotchart(sort(vi,decreasing=FALSE))
df[] <- lapply(df, function(x) if(is.character(x)) factor(x) else x)
tsdf[] <- lapply(tsdf, function(x) if(is.character(x)) factor(x) else x)
#crf1 <- cforest(SI_Binary ~ . - id, data = df, controls = cforest_unbiased(ntree = 400, mtry = 3))
# Make predictions on the testing dataset
#crfpred <- predict(crf1, newdata = tsdf, type = "response") # Error in checkData(oldData, RET) :  Levels in factors of new data do not match original data -- I checked and the levels of the race variable are different. This is because there is only one American Indian participant in the entire dataset and they were added to the training data.
#filter out the American Indian participant
df <- df %>% filter(race != "American Indian")
df$race <- factor(as.character(df$race, levels = "African American", "Asian","Pacific Islander" ,"White"))
tsdf$race <- factor(as.character(tsdf$race, levels = "African American", "Asian","Pacific Islander" ,"White"))
df[] <- lapply(df, function(x) if(is.character(x)) factor(x) else x)
crf1 <- cforest(SI_Binary ~ ., data = df, controls = cforest_unbiased(ntree = 400, mtry = 3))
crfpred <- predict(crf1, newdata = tsdf, type = "response")
crf.table=table(crfpred,tsdf$SI_Binary)
crf.table
1-(mean(crfpred==tsdf$SI_Binary))
vi=varimp(crf1)
dotchart(sort(vi,decreasing=FALSE))
trctrl=trainControl(method='cv',number=5) #k-fold cross-validation to determine the tuning parameters.
trctrl
set.seed(2000)
#Fit Model
train.rf=train(SI_Binary~.,data=df,method='rf',tuneLength=5,trControl=trctrl)
#See tuning parameters
train.rf
plot(train.rf)
final.rf=train.rf$finalModel
varImpPlot(final.rf)
